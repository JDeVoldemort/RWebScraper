# Overview

I did this project as a method of practicing the R programming language and learning more about using web scrapers.

I developed a Web Scraper to run as a script. It pulls data from a card database and uses Rvest and Dplyr to harvest info from the raw html using the css classes and ids. It also briefly processes the data and outputs a graph and prints some data to a CSV file. 

The purpose of writing this software was to try using a webscraper and use the R lauguage. 

{Provide a link to your YouTube demonstration. It should be a 4-5 minute demo of the software running and a walkthrough of the code. Focus should be on sharing what you learned about the language syntax.}

[Software Demo Video](https://youtu.be/3j53zEYcF2s)

# Development Environment

I used VSCODE, R, and the libraries: rvest, dplyr, and ggplot. I also used a chrome extentions to help gather the CSS info. 

I used R, and the libraries: rvest, dplyr, and ggplot.

# Useful Websites

{Make a list of websites that you found helpful in this project}

- [Youtube tutorial](https://www.youtube.com/watch?v=IM3PDKdSR7U)
- [What is R Article](https://www.simplilearn.com/what-is-r-article#:~:text=R%20offers%20a%20wide%20variety,for%20data%20importing%20and%20cleaning.)

# Future Work


- I would like to implement a user input function to loop search the data
- I would like to conditionally build some custom dataframes to include more and less info from categories. 
- I'd like to implement a scaper that could use different source links without a lot of recoding. 
